# [NLP] 정수 인코딩

## 정수 인코딩을 왜 쓸까?

컴퓨터는 텍스트보다 숫자를 더 잘 처리하기 때문이다. 가장 로우 레벨에서는 결국 0과 1로 연산하기 때문이다.

따라서 텍스트를 숫자로 바꾸는 과정이 필요하다. 이 과정에서 첫 번째 단계가 각 단어를 고유한 정수에 매핑(mapping) 시키는 단계가 필요하다.

즉, 이 단계가 정수 인코딩이다.

## 정수 인코딩 과정

정수 인코딩이란 텍스트를 정수 집합 벡터로 변환하는 것이다.

예를 들어, 아래 텍스트가 주어졌다.

```python
raw_text = "A barber is a person. a barber is good person. a barber is huge person. he Knew A Secret! The Secret He Kept is huge secret. Huge secret. His barber kept his word. a barber kept his word. His barber kept his secret. But keeping and keeping such a huge secret to himself was driving the barber crazy. the barber went up a huge mountain."
```

해당 텍스트에서 토큰화를 통해 단어를 추출해내고 각 단어의 빈도 수를 체크한다.

각 단어의 빈도 수를 알게 되면, 어떤 단어의 빈도 수가 높고 낮은지 알 수 있다. 빈도 수가 가장 높은 단어부터 인덱스를 부여한다.

위의 텍스트에서는 'barber'가 가장 높은 빈도 수를 보였기에 인덱스 1을 부여한다.

```python
{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5, 'word': 6, 'keeping': 7}
```

완성된 인덱스로 다시 문장을 구성한다.

```python
# 정수 인코딩 진행 전
[['barber', 'person'], ['barber', 'good', 'person'], ['barber', 'huge', 'person'], ['knew', 'secret'], ['secret', 'kept', 'huge', 'secret'], ['huge', 'secret'], ['barber', 'kept', 'word'], ['barber', 'kept', 'word'], ['barber', 'kept', 'secret'], ['keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy'], ['barber', 'went', 'huge', 'mountain']]

# 정수 인코딩 진행 후
[[1, 5], [1, 6, 5], [1, 3, 5], [6, 2], [2, 4, 3, 2], [3, 2], [1, 4, 6], [1, 4, 6], [1, 4, 2], [6, 6, 3, 2, 6, 1, 6], [1, 6, 3, 6]]
```
