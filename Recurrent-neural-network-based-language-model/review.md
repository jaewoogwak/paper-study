1. 저자가 뭘 해내고 싶어했는가?

-   perplexity reduction
-   음성 인식에 neural network 사용

2. 이 연구의 접근에서 중요한 요소는 무엇인가?

-   n-gram 방식보다 성능이 뛰어나다.
-   feedforward network는 다음 단어를 예측하기 위해 이전 5~10 단어를 보고 예측해야하는데 인간은 더 큰 context에서 본다.
-
-   cache state로 이전 상태가 현재 상태의 입력으로 들어가도록함
-   RNN으로 perplexity 감소를 보일 수 있었음

3. 당신(논문독자)은 스스로 이 논문을 이용할 수 있는가?

4. 당신이 참고하고 싶은 다른 레퍼런스에는 어떤 것이 있는가?
